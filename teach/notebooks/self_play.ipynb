{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c8da54",
   "metadata": {},
   "source": [
    "# Self-Play\n",
    "\n",
    "**Self-play** is the core training mechanism in AlphaZero where the AI plays against itself to generate training data and improve over time. This notebook explains how self-play works and how it combines MCTS and neural networks to create a continuously improving system.\n",
    "\n",
    "1. **Plays games against itself** using MCTS guided by a neural network\n",
    "2. **Records training examples** from each game (states, MCTS policies, outcomes)\n",
    "3. **Trains the neural network** on these examples to improve predictions\n",
    "4. **Repeats** the process, getting progressively stronger\n",
    "\n",
    "This creates a virtuous cycle\n",
    "\n",
    "<!-- better network → better MCTS → better training data → better network. -->\n",
    "\n",
    "```mermaid\n",
    "---\n",
    "config:\n",
    "  theme: 'base'\n",
    "  themeVariables:\n",
    "    primaryColor: '#ffffff'\n",
    "    primaryTextColor: '#4D5461'\n",
    "    primaryBorderColor: '#096bda11'\n",
    "    lineColor: '#096bda'\n",
    "    secondaryColor: '#ffffff84'\n",
    "    secondaryTextColor: '#4D5461'\n",
    "    tertiaryColor: '#4d546110'\n",
    "    tertiaryTextColor: '#4D5461'\n",
    "---\n",
    "stateDiagram-v2\n",
    "    s1: Better Neural Network\n",
    "    s2: Better MCTS\n",
    "    s3: Better Training Data\n",
    "\n",
    "    s1 --> s2\n",
    "    s2 --> s3\n",
    "    s3 --> s1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce754fbe",
   "metadata": {},
   "source": [
    "### The Loop\n",
    "```mermaid\n",
    "---\n",
    "config:\n",
    "  theme: 'base'\n",
    "  themeVariables:\n",
    "    primaryColor: '#ffffff'\n",
    "    primaryTextColor: '#4D5461'\n",
    "    primaryBorderColor: '#096bda11'\n",
    "    lineColor: '#096bda'\n",
    "    secondaryColor: '#ffffff84'\n",
    "    secondaryTextColor: '#4D5461'\n",
    "    tertiaryColor: '#4d546110'\n",
    "    tertiaryTextColor: '#4D5461'\n",
    "---\n",
    "graph TD\n",
    "    A[Initialize Game] --> B[MCTS Search]\n",
    "    B --> C[Get Move Probabilities]\n",
    "    C --> D[Sample Action]\n",
    "    D --> E[Make Move]\n",
    "    E --> F{Game Over?}\n",
    "    F -->|No| B\n",
    "    F -->|Yes| G[Record Game Outcome]\n",
    "    G --> H[Create Training Examples]\n",
    "    H --> I[Train Network]\n",
    "    I --> A\n",
    "```\n",
    "\n",
    "*Note: The diagram above illustrates the self-play loop where the agent continuously plays games against itself, collects data, and trains its neural network to improve performance over time. Self-play and Neural Network Training could be done parallely in practice for efficiency. For the purpose of clarity, they are shown sequentially here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553c167",
   "metadata": {},
   "source": [
    "## Advanced Techniques\n",
    "\n",
    "Before diving into the full self-play implementation, let's understand some critical techniques that make AlphaZero training effective:\n",
    "\n",
    "1. **Temperature**: Controls exploration vs exploitation during move selection\n",
    "2. **Dirichlet Noise**: Adds randomness at the root to ensure diverse openings\n",
    "3. **Replay Buffer**: Stores and reuses training examples across iterations\n",
    "4. **Data Augmentation**: Multiplies training data using symmetries\n",
    "\n",
    "These techniques are essential for stable learning and preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fc425",
   "metadata": {},
   "source": [
    "### 1. Temperature: Exploration vs Exploitation\n",
    "\n",
    "**Temperature** $\\tau$ controls how deterministically we select moves from MCTS visit counts.\n",
    "\n",
    "\n",
    "Temperature controls exploration vs exploitation:\n",
    "- **High temperature (1.0)**: Early game, explore different openings\n",
    "- **Low temperature (0.0)**: Late game, play the best move deterministically\n",
    "- We typically use temperature 1.0 for the first 3-5 moves, then switch to 0.0, in the case of Tic-Tac-Toe. Other games may require different schedules.\n",
    "\n",
    "Given visit counts $N(s,a)$ for each action $a$:\n",
    "\n",
    "$$\\pi(a|s) = \\frac{N(s,a)^{1/\\tau}}{\\sum_b N(s,b)^{1/\\tau}}$$\n",
    "\n",
    "Temperature does not have an upper bound, but values above 1.0 are rarely used in practice. This is same temperature concept used in LLMs for sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95e31d1",
   "metadata": {},
   "source": [
    "**Temperature Values**\n",
    "\n",
    "- **$\\tau = 1.0$** (high): Probability proportional to visit counts\n",
    "  - Explores multiple promising moves\n",
    "  - Used in opening moves to build diverse opening book\n",
    "  \n",
    "- **$\\tau = 0.0$** (low): Deterministic selection\n",
    "  - Always picks the most-visited move\n",
    "  - Used in critical positions and endgame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da8a46a",
   "metadata": {
    "tags": [
     "output-only"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstration: Temperature effect on move selection\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate visit counts from MCTS\n",
    "visit_counts = np.array([100, 80, 50, 30, 20, 10, 5, 3, 2])  # 9 possible moves\n",
    "actions = list(range(9))\n",
    "\n",
    "\n",
    "def apply_temperature(visit_counts, temperature):\n",
    "    \"\"\"Apply temperature to visit counts to get probabilities\"\"\"\n",
    "    if temperature == 0:\n",
    "        # Greedy: pick most visited\n",
    "        probs = np.zeros_like(visit_counts, dtype=float)\n",
    "        probs[np.argmax(visit_counts)] = 1.0\n",
    "        return probs\n",
    "    else:\n",
    "        # Softmax with temperature\n",
    "        counts_temp = visit_counts ** (1.0 / temperature)\n",
    "        return counts_temp / np.sum(counts_temp)\n",
    "\n",
    "\n",
    "# Compare different temperatures\n",
    "temperatures = [0.0, 0.5, 1.0]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "fig.patch.set_facecolor(\"none\")\n",
    "for idx, temp in enumerate(temperatures):\n",
    "    probs = apply_temperature(visit_counts, temp)\n",
    "    axes[idx].bar(actions, probs, color=\"#096bda\", alpha=0.7)\n",
    "    axes[idx].set_title(f\"Temperature τ = {temp}\", fontsize=14, color=\"#808080\")\n",
    "    axes[idx].set_xlabel(\"Action\", color=\"#808080\")\n",
    "    axes[idx].set_ylabel(\"Probability\", color=\"#808080\")\n",
    "    axes[idx].set_ylim(0, 1.1)\n",
    "    axes[idx].grid(axis=\"y\", alpha=0.3, color=\"#808080\")\n",
    "    axes[idx].spines[\"bottom\"].set_color(\"#808080\")\n",
    "    axes[idx].spines[\"top\"].set_color(\"#808080\")\n",
    "    axes[idx].spines[\"left\"].set_color(\"#808080\")\n",
    "    axes[idx].spines[\"right\"].set_color(\"#808080\")\n",
    "    axes[idx].set_facecolor(\"none\")\n",
    "    axes[idx].tick_params(colors=\"#777777\", which=\"both\")\n",
    "\n",
    "fig.set_alpha(0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61974f23",
   "metadata": {},
   "source": [
    "Note that for temperature $\\tau > 0$, the probablity of selecting other moves is non-zero, allowing for exploration of less-visited actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e199d9",
   "metadata": {},
   "source": [
    "**Temperature Annealing Schedule**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212c34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temperature(iteration, move_number):\n",
    "    # Early iterations: explore more\n",
    "    if iteration < 100:\n",
    "        if move_number < 3:\n",
    "            return 1.0  # High exploration in opening\n",
    "        else:\n",
    "            return 0.0  # Deterministic after opening\n",
    "    else:\n",
    "        # Later iterations: mostly deterministic\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e1eef",
   "metadata": {},
   "source": [
    "### 2. Dirichlet Noise: Ensuring Exploration at Root\n",
    "\n",
    "In $\\alpha$MCTS, the neural network can sometimes be \"too confident\" in its policy predictions, causing the search to narrow down prematurely. Dirichlet noise is a mechanism introduced to counteract this by enforcing diverse exploration, particularly during the opening phase of the game.\n",
    "\n",
    "Unlike Temperature, which affects how a final move is selected after the MCTS simulation (based on visit counts), Dirichlet noise is applied before the search begins. It directly perturbs the prior probabilities output by the neural network, but only at the root node.\n",
    "\n",
    "**The Mechanism**\n",
    "\n",
    "The prior probabilities are modified by mixing the neural network’s output with a noise vector drawn from a Dirichlet distribution. The formula ensures that the resulting values still sum to 1 (valid probabilities) while introducing controlled randomness.\n",
    "At the root node only, we modify the prior probabilities:\n",
    "\n",
    "$$P'(s,a) = (1 - \\epsilon) \\cdot P(s,a) + \\epsilon \\cdot \\eta_a$$\n",
    "\n",
    "Where:\n",
    "- $P(s,a)$: The original policy probability from the neural network.\n",
    "- $\\eta \\sim \\text{Dir}(\\alpha)$:The noise vector drawn from the Dirichlet distribution.\n",
    "- $\\alpha = 0.3$: Concentration parameter \n",
    "- $\\epsilon = 0.25$: The mixing weight. This dictates the balance; typically, the prior is 75% network policy and 25% noise.\n",
    "\n",
    "**Understanding the Intuition**\n",
    "\n",
    "The Dirichlet distribution is chosen because it is perfect for generating random probability distributions. The behavior of the noise depends heavily on the concentration parameter ($\\alpha$):Small $\\alpha$ (e.g., 0.3 for Chess): Produces \"spiky\" or sparse distributions. This means the noise will heavily boost one or two specific moves while suppressing others. This encourages the search to seriously consider a specific alternative line of play.Large $\\alpha$ (e.g., 10): Produces \"flat\" or uniform distributions. This would add a small amount of noise to every move equally, which is generally less useful for strategic exploration.\n",
    "\n",
    "**Why is this crucial?**\n",
    "\n",
    "Without Dirichlet noise, the agent suffers from confirmation bias. If the neural network initially assigns a very low probability to a strong move (perhaps due to a blind spot in its training), the MCTS will rarely explore it. By artificially boosting priors at the root, Dirichlet noise forces the search to analyze moves the network might have initially underestimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab9a56e",
   "metadata": {
    "tags": [
     "output-only"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Network suggests a strong preference for action 0\n",
    "\n",
    "\n",
    "def apply_dirichlet_noise(policy_probs, alpha=0.3, epsilon=0.25):\n",
    "    num_actions = len(policy_probs)\n",
    "    # numpy's dirichlet function\n",
    "    noise = np.random.dirichlet([alpha] * num_actions)\n",
    "    noisy_policy = (1 - epsilon) * policy_probs + epsilon * noise\n",
    "    return noisy_policy, noise\n",
    "\n",
    "\n",
    "original_policy = np.array([0.7, 0.15, 0.08, 0.04, 0.02, 0.01, 0.0, 0.0, 0.0])\n",
    "noisy_policy, noise = apply_dirichlet_noise(original_policy)\n",
    "\n",
    "# Plot original, noise and noisy policies\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes = axes.flatten()\n",
    "fig.patch.set_facecolor(\"none\")\n",
    "axes[0].bar(range(len(original_policy)), original_policy, color=\"#096bda\", alpha=0.7)\n",
    "axes[0].set_title(\"Original Policy\", fontsize=14, color=\"#808080\")\n",
    "axes[0].set_xlabel(\"Action\", color=\"#808080\")\n",
    "axes[0].set_ylabel(\"Probability\", color=\"#808080\")\n",
    "axes[0].set_ylim(0, 1.1)\n",
    "axes[0].grid(axis=\"y\", alpha=0.3, color=\"#808080\")\n",
    "axes[0].spines[\"bottom\"].set_color(\"#808080\")\n",
    "axes[0].spines[\"top\"].set_color(\"#808080\")\n",
    "axes[0].spines[\"left\"].set_color(\"#808080\")\n",
    "axes[0].spines[\"right\"].set_color(\"#808080\")\n",
    "axes[0].set_facecolor(\"none\")\n",
    "axes[0].tick_params(colors=\"#777777\", which=\"both\")\n",
    "\n",
    "axes[1].bar(range(len(noise)), noise, color=\"#da9509\", alpha=0.7)\n",
    "axes[1].set_title(\"Dirichlet Noise\", fontsize=14, color=\"#808080\")\n",
    "axes[1].set_xlabel(\"Action\", color=\"#808080\")\n",
    "axes[1].set_ylabel(\"Probability\", color=\"#808080\")\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "axes[1].grid(axis=\"y\", alpha=0.3, color=\"#808080\")\n",
    "axes[1].spines[\"bottom\"].set_color(\"#808080\")\n",
    "axes[1].spines[\"top\"].set_color(\"#808080\")\n",
    "axes[1].spines[\"left\"].set_color(\"#808080\")\n",
    "axes[1].spines[\"right\"].set_color(\"#808080\")\n",
    "axes[1].set_facecolor(\"none\")\n",
    "axes[1].tick_params(colors=\"#777777\", which=\"both\")\n",
    "\n",
    "axes[2].bar(range(len(noisy_policy)), noisy_policy, color=\"#096bda\", alpha=0.7)\n",
    "axes[2].set_title(\"Noisy Policy\", fontsize=14, color=\"#808080\")\n",
    "axes[2].set_xlabel(\"Action\", color=\"#808080\")\n",
    "axes[2].set_ylabel(\"Probability\", color=\"#808080\")\n",
    "axes[2].set_ylim(0, 1.1)\n",
    "axes[2].grid(axis=\"y\", alpha=0.3, color=\"#808080\")\n",
    "axes[2].spines[\"bottom\"].set_color(\"#808080\")\n",
    "axes[2].spines[\"top\"].set_color(\"#808080\")\n",
    "axes[2].spines[\"left\"].set_color(\"#808080\")\n",
    "axes[2].spines[\"right\"].set_color(\"#808080\")\n",
    "axes[2].set_facecolor(\"none\")\n",
    "axes[2].tick_params(colors=\"#777777\", which=\"both\")\n",
    "\n",
    "fig.set_alpha(0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d1af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def apply_dirichlet_noise(policy_probs, alpha=0.3, epsilon=0.25):\n",
    "    num_actions = len(policy_probs)\n",
    "    # numpy's dirichlet function\n",
    "    noise = np.random.dirichlet([alpha] * num_actions)\n",
    "    noisy_policy = (1 - epsilon) * policy_probs + epsilon * noise\n",
    "    return noisy_policy, noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f00bb",
   "metadata": {},
   "source": [
    "### 3. Replay Buffer\n",
    "\n",
    "The replay buffer in AlphaZero is a training data storage mechanism, First-In, First-Out (FIFO queue), that stores game experiences generated during self-play. \n",
    "\n",
    "We maintain a buffer of the last $N$ examples (e.g., 50,000). When training, we sample a random mini-batch from this buffer. This mixes positions from the current iteration with positions from several iterations ago.\n",
    "\n",
    "**Breaks Temporal Correlation:**\n",
    "\n",
    "Consecutive positions in a game are highly correlated. Neural networks learn best from Independent and Identically Distributed (IID) data. Training on correlated data causes the network to \"chase its tail,\" leading to unstable learning.\n",
    "\n",
    "**Increases Sample Efficiency & Stabilizes Learning:**\n",
    "\n",
    "Instead of discarding an experience after using it once, the replay buffer allows the agent to reuse past data multiple times for training updates, making the learning process more efficient.\n",
    "Averaging the gradients over a diverse set of uncorrelated examples reduces the variance of the updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c890c523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=50000):\n",
    "        self.buffer = []\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def add(self, example):\n",
    "        self.buffer.append(example)\n",
    "        # FIFO: Remove oldest if over capacity\n",
    "        if len(self.buffer) > self.capacity:\n",
    "            self.buffer.pop(0)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        return [self.buffer[i] for i in indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6641257",
   "metadata": {},
   "source": [
    "### 4. Data Augmentation: Exploiting Symmetries\n",
    "\n",
    "It involves multiplying the training data by applying valid geometric transformations (symmetries) to the game states. In many games, including Tic-Tac-Toe, the board has symmetries (rotations and reflections) that do not change the fundamental nature of the position. By leveraging these symmetries, we can effectively increase the size of our training dataset without needing additional self-play games.\n",
    "\n",
    "This does not work for all games. In games like Chess or Go, symmetries are more limited due to asymmetrical starting positions and piece values. However, for Tic-Tac-Toe, we can use all 8 symmetries (4 rotations and 4 reflections).\n",
    "\n",
    "It is crucial that when we transform the Board State, we must also transform the Policy (Target Probabilities) to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee2a05a",
   "metadata": {
    "tags": [
     "output-only"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"aug_7588_container\" \n",
       "     style=\"font-family: sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; color: var(--text);\">\n",
       "\n",
       "  <div style=\"padding: 20px; margin-bottom: 20px;\">\n",
       "    <p style=\"text-align: center; font-size: 13px; margin-bottom: 16px; color: #666;\">\n",
       "      Click on the <strong>Identity</strong> board to place X or O pieces.<br>\n",
       "      Watch how all 8 transformations update.\n",
       "    </p>\n",
       "  </div>\n",
       "\n",
       "  <div id=\"aug_7588_boards\" style=\"display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin-bottom: 20px;\">\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_0\" width=\"160\" height=\"190\" style=\"display:block; border: 1px solid #e1e4e8;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Identity (Click Here)</text>\n",
       "        <g id=\"aug_7588_board_0_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_1\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Rotate 90°</text>\n",
       "        <g id=\"aug_7588_board_1_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_2\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Rotate 180°</text>\n",
       "        <g id=\"aug_7588_board_2_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_3\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Rotate 270°</text>\n",
       "        <g id=\"aug_7588_board_3_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_4\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Horizontal</text>\n",
       "        <g id=\"aug_7588_board_4_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_5\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Vertical</text>\n",
       "        <g id=\"aug_7588_board_5_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_6\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Diagonal \\</text>\n",
       "        <g id=\"aug_7588_board_6_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "    <div style=\"text-align: center;\">\n",
       "      <svg id=\"aug_7588_board_7\" width=\"160\" height=\"190\" style=\"display:block;\">\n",
       "        <text x=\"80.0\" y=\"14\" text-anchor=\"middle\" \n",
       "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Diagonal /</text>\n",
       "        <g id=\"aug_7588_board_7_content\" transform=\"translate(0, 20)\"></g>\n",
       "      </svg>\n",
       "    </div>\n",
       "  </div>\n",
       "\n",
       "\n",
       "</div>\n",
       "\n",
       "<script>\n",
       "(function() {\n",
       "  const widgetId = 'aug_7588';\n",
       "  const size = 160;\n",
       "  const padding = 16;\n",
       "  const cellSize = 42.666666666666664;\n",
       "\n",
       "  // State: 0=empty, 1=X, -1=O\n",
       "  let state = [0, 1, 0, 0, 1, -1, 0, -1, 1];\n",
       "  let currentPlayer = 1; // 1=X, -1=O\n",
       "\n",
       "  // Transformation maps: how to transform index i\n",
       "  const transforms = [\n",
       "    [0, 1, 2, 3, 4, 5, 6, 7, 8],  // Identity\n",
       "    [6, 3, 0, 7, 4, 1, 8, 5, 2],  // Rotate 90°\n",
       "    [8, 7, 6, 5, 4, 3, 2, 1, 0],  // Rotate 180°\n",
       "    [2, 5, 8, 1, 4, 7, 0, 3, 6],  // Rotate 270°\n",
       "    [2, 1, 0, 5, 4, 3, 8, 7, 6],  // Flip H\n",
       "    [6, 7, 8, 3, 4, 5, 0, 1, 2],  // Flip V\n",
       "    [0, 3, 6, 1, 4, 7, 2, 5, 8],  // Flip D1\n",
       "    [8, 5, 2, 7, 4, 1, 6, 3, 0],  // Flip D2\n",
       "  ];\n",
       "\n",
       "  function applyTransform(state, transformMap) {\n",
       "    const newState = new Array(9).fill(0);\n",
       "    for (let i = 0; i < 9; i++) {\n",
       "      newState[transformMap[i]] = state[i];\n",
       "    }\n",
       "    return newState;\n",
       "  }\n",
       "\n",
       "  function drawBoard(boardIdx, boardState) {\n",
       "    const svg = document.getElementById(`${widgetId}_board_${boardIdx}_content`);\n",
       "    if (!svg) return;\n",
       "\n",
       "    // Clear\n",
       "    while (svg.firstChild) {\n",
       "      svg.removeChild(svg.firstChild);\n",
       "    }\n",
       "\n",
       "    // Grid lines\n",
       "    for (let i = 1; i < 3; i++) {\n",
       "      const x = padding + i * cellSize;\n",
       "      const y = padding + i * cellSize;\n",
       "\n",
       "      const vLine = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
       "      vLine.setAttribute('x1', x);\n",
       "      vLine.setAttribute('y1', padding);\n",
       "      vLine.setAttribute('x2', x);\n",
       "      vLine.setAttribute('y2', size - padding);\n",
       "      vLine.setAttribute('stroke', '#666');\n",
       "      vLine.setAttribute('stroke-width', '2');\n",
       "      svg.appendChild(vLine);\n",
       "\n",
       "      const hLine = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
       "      hLine.setAttribute('x1', padding);\n",
       "      hLine.setAttribute('y1', y);\n",
       "      hLine.setAttribute('x2', size - padding);\n",
       "      hLine.setAttribute('y2', y);\n",
       "      hLine.setAttribute('stroke', '#666');\n",
       "      hLine.setAttribute('stroke-width', '2');\n",
       "      svg.appendChild(hLine);\n",
       "    }\n",
       "\n",
       "    // Draw cells\n",
       "    for (let i = 0; i < 9; i++) {\n",
       "      const row = Math.floor(i / 3);\n",
       "      const col = i % 3;\n",
       "      const x = padding + col * cellSize;\n",
       "      const y = padding + row * cellSize;\n",
       "      const cx = x + cellSize / 2;\n",
       "      const cy = y + cellSize / 2;\n",
       "\n",
       "      // Clickable area only on Identity board (boardIdx === 0)\n",
       "      if (boardIdx === 0) {\n",
       "        const clickRect = document.createElementNS('http://www.w3.org/2000/svg', 'rect');\n",
       "        clickRect.setAttribute('x', x);\n",
       "        clickRect.setAttribute('y', y);\n",
       "        clickRect.setAttribute('width', cellSize);\n",
       "        clickRect.setAttribute('height', cellSize);\n",
       "        clickRect.setAttribute('fill', 'transparent');\n",
       "        clickRect.setAttribute('stroke', 'none');\n",
       "        clickRect.style.cursor = 'pointer';\n",
       "        clickRect.addEventListener('click', () => handleClick(i));\n",
       "        svg.appendChild(clickRect);\n",
       "      }\n",
       "\n",
       "      // Draw piece\n",
       "      if (boardState[i] === 1) {\n",
       "        // X\n",
       "        const sizeX = cellSize * 0.4;\n",
       "\n",
       "        const line1 = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
       "        line1.setAttribute('x1', cx - sizeX / 2);\n",
       "        line1.setAttribute('y1', cy - sizeX / 2);\n",
       "        line1.setAttribute('x2', cx + sizeX / 2);\n",
       "        line1.setAttribute('y2', cy + sizeX / 2);\n",
       "        line1.setAttribute('stroke', '#0969da');\n",
       "        line1.setAttribute('stroke-width', '3');\n",
       "        line1.setAttribute('stroke-linecap', 'round');\n",
       "        svg.appendChild(line1);\n",
       "\n",
       "        const line2 = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
       "        line2.setAttribute('x1', cx + sizeX / 2);\n",
       "        line2.setAttribute('y1', cy - sizeX / 2);\n",
       "        line2.setAttribute('x2', cx - sizeX / 2);\n",
       "        line2.setAttribute('y2', cy + sizeX / 2);\n",
       "        line2.setAttribute('stroke', '#0969da');\n",
       "        line2.setAttribute('stroke-width', '3');\n",
       "        line2.setAttribute('stroke-linecap', 'round');\n",
       "        svg.appendChild(line2);\n",
       "      } else if (boardState[i] === -1) {\n",
       "        // O\n",
       "        const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');\n",
       "        circle.setAttribute('cx', cx);\n",
       "        circle.setAttribute('cy', cy);\n",
       "        circle.setAttribute('r', cellSize * 0.2);\n",
       "        circle.setAttribute('fill', 'none');\n",
       "        circle.setAttribute('stroke', '#DA7A09');\n",
       "        circle.setAttribute('stroke-width', '3');\n",
       "        svg.appendChild(circle);\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function handleClick(cellIndex) {\n",
       "    if (state[cellIndex] === 0) {\n",
       "      // Place current player's piece\n",
       "      state[cellIndex] = currentPlayer;\n",
       "      currentPlayer = -currentPlayer; // Switch player\n",
       "    } else {\n",
       "      // Clear cell\n",
       "      state[cellIndex] = 0;\n",
       "    }\n",
       "    updateAllBoards();\n",
       "  }\n",
       "\n",
       "  function updateAllBoards() {\n",
       "    for (let i = 0; i < 8; i++) {\n",
       "      const transformedState = applyTransform(state, transforms[i]);\n",
       "      drawBoard(i, transformedState);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  // Initialize\n",
       "  updateAllBoards();\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "class DataAugmentationDemo:\n",
    "    def __init__(self):\n",
    "        self.size = 160\n",
    "        self.padding = 16\n",
    "        self.cell_size = (self.size - self.padding * 2) / 3\n",
    "        self.widget_id = f\"aug_{random.randint(1000, 9999)}\"\n",
    "\n",
    "    def generate_html(self):\n",
    "        html = f\"\"\"\n",
    "<div id=\"{self.widget_id}_container\" \n",
    "     style=\"font-family: sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; color: var(--text);\">\n",
    "  \n",
    "  <div style=\"padding: 20px; margin-bottom: 20px;\">\n",
    "    <p style=\"text-align: center; font-size: 13px; margin-bottom: 16px; color: #666;\">\n",
    "      Click on the <strong>Identity</strong> board to place X or O pieces.<br>\n",
    "      Watch how all 8 transformations update.\n",
    "    </p>\n",
    "  </div>\n",
    "\n",
    "  <div id=\"{self.widget_id}_boards\" style=\"display: grid; grid-template-columns: repeat(4, 1fr); gap: 20px; margin-bottom: 20px;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_0\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block; border: 1px solid #e1e4e8;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Identity (Click Here)</text>\n",
    "        <g id=\"{self.widget_id}_board_0_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_1\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Rotate 90°</text>\n",
    "        <g id=\"{self.widget_id}_board_1_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_2\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Rotate 180°</text>\n",
    "        <g id=\"{self.widget_id}_board_2_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_3\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Rotate 270°</text>\n",
    "        <g id=\"{self.widget_id}_board_3_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_4\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Horizontal</text>\n",
    "        <g id=\"{self.widget_id}_board_4_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_5\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Vertical</text>\n",
    "        <g id=\"{self.widget_id}_board_5_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_6\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Diagonal \\\\</text>\n",
    "        <g id=\"{self.widget_id}_board_6_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <svg id=\"{self.widget_id}_board_7\" width=\"{self.size}\" height=\"{self.size + 30}\" style=\"display:block;\">\n",
    "        <text x=\"{self.size / 2}\" y=\"14\" text-anchor=\"middle\" \n",
    "              fill=\"#4D5461\" font-family=\"sans-serif\" font-size=\"12\" font-weight=\"600\">Flip Diagonal /</text>\n",
    "        <g id=\"{self.widget_id}_board_7_content\" transform=\"translate(0, 20)\"></g>\n",
    "      </svg>\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "(function() {{\n",
    "  const widgetId = '{self.widget_id}';\n",
    "  const size = {self.size};\n",
    "  const padding = {self.padding};\n",
    "  const cellSize = {self.cell_size};\n",
    "  \n",
    "  // State: 0=empty, 1=X, -1=O\n",
    "  let state = [0, 1, 0, 0, 1, -1, 0, -1, 1];\n",
    "  let currentPlayer = 1; // 1=X, -1=O\n",
    "  \n",
    "  // Transformation maps: how to transform index i\n",
    "  const transforms = [\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8],  // Identity\n",
    "    [6, 3, 0, 7, 4, 1, 8, 5, 2],  // Rotate 90°\n",
    "    [8, 7, 6, 5, 4, 3, 2, 1, 0],  // Rotate 180°\n",
    "    [2, 5, 8, 1, 4, 7, 0, 3, 6],  // Rotate 270°\n",
    "    [2, 1, 0, 5, 4, 3, 8, 7, 6],  // Flip H\n",
    "    [6, 7, 8, 3, 4, 5, 0, 1, 2],  // Flip V\n",
    "    [0, 3, 6, 1, 4, 7, 2, 5, 8],  // Flip D1\n",
    "    [8, 5, 2, 7, 4, 1, 6, 3, 0],  // Flip D2\n",
    "  ];\n",
    "  \n",
    "  function applyTransform(state, transformMap) {{\n",
    "    const newState = new Array(9).fill(0);\n",
    "    for (let i = 0; i < 9; i++) {{\n",
    "      newState[transformMap[i]] = state[i];\n",
    "    }}\n",
    "    return newState;\n",
    "  }}\n",
    "  \n",
    "  function drawBoard(boardIdx, boardState) {{\n",
    "    const svg = document.getElementById(`${{widgetId}}_board_${{boardIdx}}_content`);\n",
    "    if (!svg) return;\n",
    "    \n",
    "    // Clear\n",
    "    while (svg.firstChild) {{\n",
    "      svg.removeChild(svg.firstChild);\n",
    "    }}\n",
    "    \n",
    "    // Grid lines\n",
    "    for (let i = 1; i < 3; i++) {{\n",
    "      const x = padding + i * cellSize;\n",
    "      const y = padding + i * cellSize;\n",
    "      \n",
    "      const vLine = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
    "      vLine.setAttribute('x1', x);\n",
    "      vLine.setAttribute('y1', padding);\n",
    "      vLine.setAttribute('x2', x);\n",
    "      vLine.setAttribute('y2', size - padding);\n",
    "      vLine.setAttribute('stroke', '#666');\n",
    "      vLine.setAttribute('stroke-width', '2');\n",
    "      svg.appendChild(vLine);\n",
    "      \n",
    "      const hLine = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
    "      hLine.setAttribute('x1', padding);\n",
    "      hLine.setAttribute('y1', y);\n",
    "      hLine.setAttribute('x2', size - padding);\n",
    "      hLine.setAttribute('y2', y);\n",
    "      hLine.setAttribute('stroke', '#666');\n",
    "      hLine.setAttribute('stroke-width', '2');\n",
    "      svg.appendChild(hLine);\n",
    "    }}\n",
    "    \n",
    "    // Draw cells\n",
    "    for (let i = 0; i < 9; i++) {{\n",
    "      const row = Math.floor(i / 3);\n",
    "      const col = i % 3;\n",
    "      const x = padding + col * cellSize;\n",
    "      const y = padding + row * cellSize;\n",
    "      const cx = x + cellSize / 2;\n",
    "      const cy = y + cellSize / 2;\n",
    "      \n",
    "      // Clickable area only on Identity board (boardIdx === 0)\n",
    "      if (boardIdx === 0) {{\n",
    "        const clickRect = document.createElementNS('http://www.w3.org/2000/svg', 'rect');\n",
    "        clickRect.setAttribute('x', x);\n",
    "        clickRect.setAttribute('y', y);\n",
    "        clickRect.setAttribute('width', cellSize);\n",
    "        clickRect.setAttribute('height', cellSize);\n",
    "        clickRect.setAttribute('fill', 'transparent');\n",
    "        clickRect.setAttribute('stroke', 'none');\n",
    "        clickRect.style.cursor = 'pointer';\n",
    "        clickRect.addEventListener('click', () => handleClick(i));\n",
    "        svg.appendChild(clickRect);\n",
    "      }}\n",
    "      \n",
    "      // Draw piece\n",
    "      if (boardState[i] === 1) {{\n",
    "        // X\n",
    "        const sizeX = cellSize * 0.4;\n",
    "        \n",
    "        const line1 = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
    "        line1.setAttribute('x1', cx - sizeX / 2);\n",
    "        line1.setAttribute('y1', cy - sizeX / 2);\n",
    "        line1.setAttribute('x2', cx + sizeX / 2);\n",
    "        line1.setAttribute('y2', cy + sizeX / 2);\n",
    "        line1.setAttribute('stroke', '#0969da');\n",
    "        line1.setAttribute('stroke-width', '3');\n",
    "        line1.setAttribute('stroke-linecap', 'round');\n",
    "        svg.appendChild(line1);\n",
    "        \n",
    "        const line2 = document.createElementNS('http://www.w3.org/2000/svg', 'line');\n",
    "        line2.setAttribute('x1', cx + sizeX / 2);\n",
    "        line2.setAttribute('y1', cy - sizeX / 2);\n",
    "        line2.setAttribute('x2', cx - sizeX / 2);\n",
    "        line2.setAttribute('y2', cy + sizeX / 2);\n",
    "        line2.setAttribute('stroke', '#0969da');\n",
    "        line2.setAttribute('stroke-width', '3');\n",
    "        line2.setAttribute('stroke-linecap', 'round');\n",
    "        svg.appendChild(line2);\n",
    "      }} else if (boardState[i] === -1) {{\n",
    "        // O\n",
    "        const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');\n",
    "        circle.setAttribute('cx', cx);\n",
    "        circle.setAttribute('cy', cy);\n",
    "        circle.setAttribute('r', cellSize * 0.2);\n",
    "        circle.setAttribute('fill', 'none');\n",
    "        circle.setAttribute('stroke', '#DA7A09');\n",
    "        circle.setAttribute('stroke-width', '3');\n",
    "        svg.appendChild(circle);\n",
    "      }}\n",
    "    }}\n",
    "  }}\n",
    "  \n",
    "  function handleClick(cellIndex) {{\n",
    "    if (state[cellIndex] === 0) {{\n",
    "      // Place current player's piece\n",
    "      state[cellIndex] = currentPlayer;\n",
    "      currentPlayer = -currentPlayer; // Switch player\n",
    "    }} else {{\n",
    "      // Clear cell\n",
    "      state[cellIndex] = 0;\n",
    "    }}\n",
    "    updateAllBoards();\n",
    "  }}\n",
    "  \n",
    "  function updateAllBoards() {{\n",
    "    for (let i = 0; i < 8; i++) {{\n",
    "      const transformedState = applyTransform(state, transforms[i]);\n",
    "      drawBoard(i, transformedState);\n",
    "    }}\n",
    "  }}\n",
    "  \n",
    "  // Initialize\n",
    "  updateAllBoards();\n",
    "}})();\n",
    "</script>\n",
    "\"\"\"\n",
    "        return html\n",
    "\n",
    "    def show(self):\n",
    "        display(HTML(self.generate_html()))\n",
    "\n",
    "\n",
    "# Create and display\n",
    "aug_demo = DataAugmentationDemo()\n",
    "aug_demo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed95497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_symmetries():\n",
    "    \"\"\"Generate all 8 symmetries using just Rot90 and Flip.\"\"\"\n",
    "    # 1. Define the two base transformations (Destination Maps)\n",
    "    #    Indices: 0 1 2\n",
    "    #             3 4 5\n",
    "    #             6 7 8\n",
    "\n",
    "    # Rotate 90°: 0->2, 1->5, 2->8...\n",
    "    rot90 = [2, 5, 8, 1, 4, 7, 0, 3, 6]\n",
    "    # Vertical Flip (swap rows): 0->6, 1->7, 2->8...\n",
    "    flip = [6, 7, 8, 3, 4, 5, 0, 1, 2]\n",
    "\n",
    "    # 2. Generate all 8 permutations by composing them\n",
    "    #    Start with Identity [0, 1, ... 8]\n",
    "    perms = [list(range(9))]\n",
    "\n",
    "    # Generate 3 rotations: Rot90, Rot180, Rot270\n",
    "    for _ in range(3):\n",
    "        # Apply rot90 to the last permutation\n",
    "        perms.append([rot90[i] for i in perms[-1]])\n",
    "\n",
    "    # Generate 4 reflections: Flip every rotation\n",
    "    # Apply flip to every existing permutation\n",
    "    perms += [[flip[i] for i in p] for p in perms]\n",
    "\n",
    "    return perms\n",
    "\n",
    "\n",
    "def augment_data(examples):\n",
    "    \"\"\"Expand dataset 8x by applying symmetries.\"\"\"\n",
    "    perms = _get_symmetries()\n",
    "    augmented = []\n",
    "\n",
    "    for state, policy, value in examples:\n",
    "        # Standardize input format\n",
    "        board, player = state\n",
    "        # Convert dict policy to list if needed\n",
    "        if isinstance(policy, dict):\n",
    "            policy = [policy.get(i, 0.0) for i in range(9)]\n",
    "\n",
    "        for p in perms:\n",
    "            # 1. Transform Board\n",
    "            # p[i] is the NEW index for the item at OLD index i\n",
    "            new_board = [0] * 9\n",
    "            for i, val in enumerate(board):\n",
    "                new_board[p[i]] = val\n",
    "\n",
    "            # 2. Transform Policy\n",
    "            # The probability for move 'i' must move to 'p[i]'\n",
    "            new_policy = [0.0] * 9\n",
    "            for i, prob in enumerate(policy):\n",
    "                new_policy[p[i]] = prob\n",
    "\n",
    "            augmented.append(((tuple(new_board), player), new_policy, value))\n",
    "\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747ad40",
   "metadata": {},
   "source": [
    "## Self-Play Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faec073",
   "metadata": {},
   "source": [
    "### $\\alpha$MCTS\n",
    "\n",
    "Now with Dirichlet noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc4bf6a",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MCTS classes defined\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MCTSNode:\n",
    "    \"\"\"A node in the Monte Carlo Tree Search tree\"\"\"\n",
    "\n",
    "    def __init__(self, state, parent=None, action=None, prior=0):\n",
    "        self.state = state  # Game state (tuple of board, player)\n",
    "        self.parent = parent  # Parent node\n",
    "        self.action = action  # Action that led to this node\n",
    "        self.children = {}  # Dict mapping actions to child nodes\n",
    "\n",
    "        # MCTS statistics\n",
    "        self.visit_count = 0  # N(s,a): number of visits\n",
    "        self.value_sum = 0.0  # W(s,a): sum of values from simulations\n",
    "        self.prior = prior  # P(s,a): neural network prior probability\n",
    "\n",
    "    def is_expanded(self):\n",
    "        \"\"\"Check if this node has children\"\"\"\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def value(self):\n",
    "        \"\"\"Average value Q(s,a) = W(s,a) / N(s,a)\"\"\"\n",
    "        if self.visit_count == 0:\n",
    "            return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "    def q_from_parent_view(self):\n",
    "        \"\"\"Return Q value from parent's perspective (negated)\"\"\"\n",
    "        return -self.value()\n",
    "\n",
    "    def ucb_score(self, c_puct=1.0):\n",
    "        \"\"\"\n",
    "        Calculate PUCT score: Q(s,a) + U(s,a)\n",
    "        U(s,a) = c_puct * P(s,a) * sqrt(N(parent)) / (1 + N(s,a))\n",
    "        \"\"\"\n",
    "        parent_N = 1 + (self.parent.visit_count if self.parent else 0)\n",
    "        U = c_puct * self.prior * (np.sqrt(parent_N) / (1 + self.visit_count))\n",
    "        Q = self.q_from_parent_view()\n",
    "        return Q + U\n",
    "\n",
    "    def select_child(self, c_puct=1.0):\n",
    "        \"\"\"Select child with maximum PUCT score\"\"\"\n",
    "        return max(self.children.values(), key=lambda ch: ch.ucb_score(c_puct))\n",
    "\n",
    "    def expand(self, game, action_probs):\n",
    "        \"\"\"Create child nodes for all legal actions\"\"\"\n",
    "        for action, prob in action_probs:\n",
    "            if action not in self.children:\n",
    "                new_state = game.copy()\n",
    "                new_state.make_move(action)\n",
    "                self.children[action] = MCTSNode(\n",
    "                    state=new_state.state(), parent=self, action=action, prior=prob\n",
    "                )\n",
    "\n",
    "    def backup(self, value):\n",
    "        \"\"\"Propagate value up the tree (negating at each level)\"\"\"\n",
    "        self.visit_count += 1\n",
    "        self.value_sum += value\n",
    "        if self.parent:\n",
    "            self.parent.backup(-value)  # Negate for opponent's perspective\n",
    "\n",
    "\n",
    "class AlphaZeroMCTS:\n",
    "    \"\"\"MCTS search guided by a neural network\"\"\"\n",
    "\n",
    "    def __init__(self, game, model, c_puct=1.0, num_simulations=100):\n",
    "        self.game = game\n",
    "        self.model = model\n",
    "        self.c_puct = c_puct\n",
    "        self.num_simulations = num_simulations\n",
    "\n",
    "    def search(self, root_state):\n",
    "        \"\"\"Run MCTS simulations from root_state and return root node\"\"\"\n",
    "        root = MCTSNode(root_state)\n",
    "\n",
    "        # Expand root with Dirichlet noise for exploration\n",
    "        game_copy_root = self.game.copy()\n",
    "        if not game_copy_root.over():\n",
    "            v_root, policy_root = self.model.predict(game_copy_root)\n",
    "            legal = game_copy_root.valid_moves()\n",
    "            probs = [(a, policy_root[a]) for a in legal]\n",
    "            s = sum(p for _, p in probs)\n",
    "            if s > 0:\n",
    "                probs = [(a, p / s) for a, p in probs]\n",
    "            # Add Dirichlet noise to root for exploration\n",
    "            if probs:\n",
    "                alpha, eps = 0.3, 0.25\n",
    "                noise = np.random.dirichlet([alpha] * len(probs))\n",
    "                probs = [\n",
    "                    (a, (1 - eps) * p + eps * n) for (a, p), n in zip(probs, noise)\n",
    "                ]\n",
    "            root.expand(game_copy_root, probs)\n",
    "\n",
    "        # Run simulations\n",
    "        for _ in range(self.num_simulations):\n",
    "            node = root\n",
    "            game_copy = self.game.copy()\n",
    "\n",
    "            # Selection: traverse tree using PUCT\n",
    "            while node.is_expanded() and not game_copy.over():\n",
    "                node = node.select_child(self.c_puct)\n",
    "                game_copy.make_move(node.action)\n",
    "\n",
    "            # Expansion & Evaluation\n",
    "            if not game_copy.over():\n",
    "                v, policy = self.model.predict(game_copy)\n",
    "                legal = game_copy.valid_moves()\n",
    "                probs = [(a, policy[a]) for a in legal]\n",
    "                s = sum(p for _, p in probs)\n",
    "                if s > 0:\n",
    "                    probs = [(a, p / s) for a, p in probs]\n",
    "                node.expand(game_copy, probs)\n",
    "                node.backup(v)\n",
    "            else:\n",
    "                # Terminal node: use game outcome\n",
    "                terminal_v = game_copy.score() * game_copy.current_player\n",
    "                node.backup(terminal_v)\n",
    "\n",
    "        return root\n",
    "\n",
    "    def get_action_probabilities(self, root_state, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Get move probabilities from MCTS visit counts\n",
    "\n",
    "        Args:\n",
    "            temperature: Controls randomness\n",
    "                - temp=1.0: proportional to visit counts\n",
    "                - temp=0.0: deterministic (pick most visited)\n",
    "        \"\"\"\n",
    "        root = self.search(root_state)\n",
    "\n",
    "        actions = []\n",
    "        visit_counts = []\n",
    "\n",
    "        for action, child in root.children.items():\n",
    "            actions.append(action)\n",
    "            visit_counts.append(child.visit_count)\n",
    "\n",
    "        if temperature == 0:\n",
    "            # Greedy: pick best action\n",
    "            best_action_idx = np.argmax(visit_counts)\n",
    "            probs = np.zeros(len(actions))\n",
    "            probs[best_action_idx] = 1.0\n",
    "        else:\n",
    "            # Softmax with temperature\n",
    "            visit_counts = np.array(visit_counts)\n",
    "            visit_counts = visit_counts ** (1.0 / temperature)\n",
    "            probs = visit_counts / np.sum(visit_counts)\n",
    "\n",
    "        return actions, probs\n",
    "\n",
    "\n",
    "print(\"✓ MCTS classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b349e",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "723ee371",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Neural network classes defined\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with skip connection\"\"\"\n",
    "\n",
    "    def __init__(self, num_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            num_channels, num_channels, kernel_size=3, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            num_channels, num_channels, kernel_size=3, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += residual  # Skip connection\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class AlphaZeroNet(nn.Module):\n",
    "    \"\"\"Neural network with policy and value heads\"\"\"\n",
    "\n",
    "    def __init__(self, game_channels=2, num_res_blocks=4, action_size=9, board_size=3):\n",
    "        super().__init__()\n",
    "        self.num_channels = 64\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv_input = nn.Conv2d(\n",
    "            game_channels, self.num_channels, kernel_size=3, padding=1, bias=False\n",
    "        )\n",
    "        self.bn_input = nn.BatchNorm2d(self.num_channels)\n",
    "\n",
    "        # Residual tower\n",
    "        self.res_blocks = nn.ModuleList(\n",
    "            [ResidualBlock(self.num_channels) for _ in range(num_res_blocks)]\n",
    "        )\n",
    "\n",
    "        # Policy head: predicts move probabilities\n",
    "        self.p_conv = nn.Conv2d(self.num_channels, 2, kernel_size=1, bias=False)\n",
    "        self.p_bn = nn.BatchNorm2d(2)\n",
    "        self.p_fc = nn.Linear(2 * board_size * board_size, action_size)\n",
    "\n",
    "        # Value head: predicts position evaluation\n",
    "        self.v_conv = nn.Conv2d(self.num_channels, 1, kernel_size=1, bias=False)\n",
    "        self.v_bn = nn.BatchNorm2d(1)\n",
    "        self.v_fc1 = nn.Linear(1 * board_size * board_size, 64)\n",
    "        self.v_fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, Channels, Height, Width)\n",
    "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
    "\n",
    "        # Residual tower\n",
    "        for res_block in self.res_blocks:\n",
    "            x = res_block(x)\n",
    "\n",
    "        # Policy head\n",
    "        p = F.relu(self.p_bn(self.p_conv(x)))\n",
    "        p = p.view(p.size(0), -1)  # Flatten\n",
    "        policy_logits = self.p_fc(p)\n",
    "\n",
    "        # Value head\n",
    "        v = F.relu(self.v_bn(self.v_conv(x)))\n",
    "        v = v.view(v.size(0), -1)  # Flatten\n",
    "        v = F.relu(self.v_fc1(v))\n",
    "        v = torch.tanh(self.v_fc2(v))  # Value in [-1, 1]\n",
    "\n",
    "        return v.squeeze(-1), policy_logits\n",
    "\n",
    "\n",
    "class AlphaZeroModel:\n",
    "    \"\"\"Wrapper for neural network with training and inference\"\"\"\n",
    "\n",
    "    def __init__(self, board_size=3, action_size=9, learning_rate=0.001):\n",
    "        self.board_size = board_size\n",
    "        self.action_size = action_size\n",
    "        self.net = AlphaZeroNet(action_size=action_size, board_size=board_size)\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.net.parameters(), lr=learning_rate, weight_decay=1e-4\n",
    "        )\n",
    "        self.training_data = []\n",
    "\n",
    "    def encode_state(self, game):\n",
    "        \"\"\"\n",
    "        Convert game state to network input [2, board_size, board_size]\n",
    "        Channel 0: current player's pieces\n",
    "        Channel 1: opponent's pieces\n",
    "        \"\"\"\n",
    "        if hasattr(game, \"board\") and hasattr(game, \"current_player\"):\n",
    "            board = np.array(game.board).reshape(self.board_size, self.board_size)\n",
    "            cur = game.current_player\n",
    "        else:\n",
    "            # Stored (state, player) pair\n",
    "            board = np.array(game[0]).reshape(self.board_size, self.board_size)\n",
    "            cur = game[1]\n",
    "\n",
    "        current_plane = (board == cur).astype(np.float32)\n",
    "        opponent_plane = (board == -cur).astype(np.float32)\n",
    "        return np.stack([current_plane, opponent_plane], axis=0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, game):\n",
    "        \"\"\"Get value and policy predictions for a game state\"\"\"\n",
    "        self.net.eval()\n",
    "        state = self.encode_state(game)\n",
    "        x = torch.from_numpy(state).unsqueeze(0)  # Add batch dimension\n",
    "        value, policy_logits = self.net(x)\n",
    "\n",
    "        value = float(value[0])\n",
    "        policy = F.softmax(policy_logits[0], dim=0).numpy()\n",
    "        return value, policy\n",
    "\n",
    "    def add_training_data(self, state, action_probs, value):\n",
    "        \"\"\"Add a training example to the replay buffer\"\"\"\n",
    "        self.training_data.append((state, action_probs, value))\n",
    "        # Keep buffer size manageable\n",
    "        if len(self.training_data) > 50000:\n",
    "            self.training_data = self.training_data[-50000:]\n",
    "\n",
    "    def train(self, batch_size=64, epochs=10):\n",
    "        \"\"\"Train the network on collected self-play data\"\"\"\n",
    "        if len(self.training_data) < batch_size:\n",
    "            return\n",
    "\n",
    "        self.net.train()\n",
    "\n",
    "        # Prepare training batch\n",
    "        states, values, policies = [], [], []\n",
    "        for state, action_probs, value in self.training_data:\n",
    "            states.append(self.encode_state(state))\n",
    "            values.append(value)\n",
    "\n",
    "            # Convert action_probs dict to array\n",
    "            if isinstance(action_probs, dict):\n",
    "                policy = np.zeros(self.action_size, dtype=np.float32)\n",
    "                for action, prob in action_probs.items():\n",
    "                    policy[action] = prob\n",
    "            else:\n",
    "                policy = np.array(action_probs, dtype=np.float32)\n",
    "            policies.append(policy)\n",
    "\n",
    "        states = torch.from_numpy(np.array(states))\n",
    "        values = torch.tensor(values, dtype=torch.float32)\n",
    "        policies = torch.from_numpy(np.array(policies))\n",
    "\n",
    "        # Training loop\n",
    "        dataset_size = len(states)\n",
    "        for epoch in range(epochs):\n",
    "            indices = torch.randperm(dataset_size)\n",
    "            for i in range(0, dataset_size, batch_size):\n",
    "                batch_indices = indices[i : i + batch_size]\n",
    "                batch_states = states[batch_indices]\n",
    "                batch_values = values[batch_indices]\n",
    "                batch_policies = policies[batch_indices]\n",
    "\n",
    "                # Forward pass\n",
    "                pred_values, pred_logits = self.net(batch_states)\n",
    "\n",
    "                # Loss computation\n",
    "                value_loss = F.mse_loss(pred_values, batch_values)\n",
    "                policy_loss = (\n",
    "                    -torch.sum(batch_policies * F.log_softmax(pred_logits, dim=1))\n",
    "                    / batch_size\n",
    "                )\n",
    "                total_loss = value_loss + policy_loss\n",
    "\n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "print(\"✓ Neural network classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557e01f",
   "metadata": {},
   "source": [
    "### Game class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe75f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Tic-Tac-Toe game implementation for demonstration\n",
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = [0] * 9  # 0=empty, 1=X, -1=O\n",
    "        self.current_player = 1\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"Create a copy of the game\"\"\"\n",
    "        new_game = TicTacToe()\n",
    "        new_game.board = self.board.copy()\n",
    "        new_game.current_player = self.current_player\n",
    "        return new_game\n",
    "\n",
    "    def state(self):\n",
    "        \"\"\"Return state as (board_tuple, player)\"\"\"\n",
    "        return (tuple(self.board), self.current_player)\n",
    "\n",
    "    def valid_moves(self):\n",
    "        \"\"\"Return list of valid moves\"\"\"\n",
    "        return [i for i in range(9) if self.board[i] == 0]\n",
    "\n",
    "    def make_move(self, action):\n",
    "        \"\"\"Make a move\"\"\"\n",
    "        if self.board[action] != 0:\n",
    "            raise ValueError(f\"Invalid move: {action}\")\n",
    "        self.board[action] = self.current_player\n",
    "        self.current_player = -self.current_player\n",
    "\n",
    "    def over(self):\n",
    "        \"\"\"Check if game is over\"\"\"\n",
    "        return self.score() != 0 or len(self.valid_moves()) == 0\n",
    "\n",
    "    def score(self):\n",
    "        \"\"\"Return 1 if X wins, -1 if O wins, 0 otherwise\"\"\"\n",
    "        lines = [\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8],  # rows\n",
    "            [0, 3, 6],\n",
    "            [1, 4, 7],\n",
    "            [2, 5, 8],  # columns\n",
    "            [0, 4, 8],\n",
    "            [2, 4, 6],  # diagonals\n",
    "        ]\n",
    "        for line in lines:\n",
    "            if self.board[line[0]] == self.board[line[1]] == self.board[line[2]] != 0:\n",
    "                return self.board[line[0]]\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da607710",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b204a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AlphaZero Model...\n",
      "\n",
      "=== Iteration 1 / 5 ===\n",
      "Self-playing 20 episodes... 5.. 10.. 15.. 20.. \n",
      "Generated 153 examples.\n",
      "Augmented to 1224 examples (Exploiting symmetries).\n",
      "Training Neural Network on 1224 cached examples...\n",
      "Iteration complete in 12.6s\n",
      "\n",
      "=== Iteration 2 / 5 ===\n",
      "Self-playing 20 episodes... 5.. 10.. 15.. 20.. \n",
      "Generated 146 examples.\n",
      "Augmented to 1168 examples (Exploiting symmetries).\n",
      "Training Neural Network on 2392 cached examples...\n",
      "Iteration complete in 11.8s\n",
      "\n",
      "=== Iteration 3 / 5 ===\n",
      "Self-playing 20 episodes... 5.. 10.. 15.. 20.. \n",
      "Generated 143 examples.\n",
      "Augmented to 1144 examples (Exploiting symmetries).\n",
      "Training Neural Network on 3536 cached examples...\n",
      "Iteration complete in 13.8s\n",
      "\n",
      "=== Iteration 4 / 5 ===\n",
      "Self-playing 20 episodes... 5.. 10.. 15.. 20.. \n",
      "Generated 155 examples.\n",
      "Augmented to 1240 examples (Exploiting symmetries).\n",
      "Training Neural Network on 4776 cached examples...\n",
      "Iteration complete in 12.2s\n",
      "\n",
      "=== Iteration 5 / 5 ===\n",
      "Self-playing 20 episodes... 5.. 10.. 15.. 20.. \n",
      "Generated 167 examples.\n",
      "Augmented to 1336 examples (Exploiting symmetries).\n",
      "Training Neural Network on 6112 cached examples...\n",
      "Iteration complete in 14.1s\n",
      "\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "NUM_ITERATIONS = 5  # Total training loops\n",
    "EPISODES_PER_ITER = 20  # Self-play games to play per iteration\n",
    "MCTS_SIMS = 50  # MCTS simulations per move\n",
    "BATCH_SIZE = 64  # Training batch size\n",
    "EPOCHS = 5  # Training epochs per iteration\n",
    "TEMPERATURE_THRESHOLD = 6  # Moves before temperature drops to 0 (exploitation)\n",
    "\n",
    "\n",
    "def execute_episode(model):\n",
    "    \"\"\"\n",
    "    Plays one game of self-play and returns a list of training examples.\n",
    "    Returns: list of (state, policy_vector, value)\n",
    "    \"\"\"\n",
    "    game = TicTacToe()\n",
    "    mcts = AlphaZeroMCTS(game, model, c_puct=1.0, num_simulations=MCTS_SIMS)\n",
    "    examples = []  # Stores (state, policy, current_player)\n",
    "    move_count = 0\n",
    "\n",
    "    while not game.over():\n",
    "        # 1. Get MCTS policy\n",
    "        # Use high temp for exploration early in game, low temp later\n",
    "        temp = 1.0 if move_count < TEMPERATURE_THRESHOLD else 0.1\n",
    "\n",
    "        # get_action_probabilities returns valid actions and their probs\n",
    "        # We assume get_action_probabilities expects the root state\n",
    "        valid_actions, valid_probs = mcts.get_action_probabilities(\n",
    "            game.state(), temperature=temp\n",
    "        )\n",
    "\n",
    "        # 2. Create full policy vector (size 9)\n",
    "        policy = np.zeros(9)\n",
    "        for action, prob in zip(valid_actions, valid_probs):\n",
    "            policy[action] = prob\n",
    "\n",
    "        # Store example: (state, policy, current_player)\n",
    "        # We store current_player to calculate the value later based on the winner\n",
    "        examples.append([game.state(), policy, game.current_player])\n",
    "\n",
    "        # 3. Choose action\n",
    "        # In self-play, we sample from the distribution to ensure diversity\n",
    "        action = np.random.choice(valid_actions, p=valid_probs)\n",
    "        game.make_move(action)\n",
    "        move_count += 1\n",
    "\n",
    "    # 4. Determine game outcome (Value)\n",
    "    # score() returns 1 (X wins), -1 (O wins), or 0 (Draw)\n",
    "    outcome = game.score()\n",
    "\n",
    "    # 5. Assign value to each example relative to the player at that step\n",
    "    processed_examples = []\n",
    "    for state, policy, player in examples:\n",
    "        # If player was X (1) and X won (1), value is 1\n",
    "        # If player was O (-1) and X won (1), value is -1\n",
    "        # If outcome is draw (0), value is 0\n",
    "        value = outcome * player\n",
    "        processed_examples.append((state, policy, value))\n",
    "\n",
    "    return processed_examples\n",
    "\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "\n",
    "# 1. Initialize Model\n",
    "print(\"Initializing AlphaZero Model...\")\n",
    "model = AlphaZeroModel(board_size=3, action_size=9)\n",
    "\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(f\"\\n=== Iteration {iteration + 1} / {NUM_ITERATIONS} ===\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 2. Self-Play Phase\n",
    "    iteration_examples = []\n",
    "    print(f\"Self-playing {EPISODES_PER_ITER} episodes...\", end=\" \", flush=True)\n",
    "\n",
    "    for i in range(EPISODES_PER_ITER):\n",
    "        # Run one episode\n",
    "        episode_data = execute_episode(model)\n",
    "        iteration_examples.extend(episode_data)\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"{i + 1}..\", end=\" \", flush=True)\n",
    "\n",
    "    print(f\"\\nGenerated {len(iteration_examples)} examples.\")\n",
    "\n",
    "    # 3. Data Augmentation Phase\n",
    "    # Use the augment_data function defined in the notebook\n",
    "    augmented_examples = augment_data(iteration_examples)\n",
    "    print(f\"Augmented to {len(augmented_examples)} examples (Exploiting symmetries).\")\n",
    "\n",
    "    # 4. Replay Buffer Storage\n",
    "    # Add all new examples to the model's sliding window memory\n",
    "    for state, policy, value in augmented_examples:\n",
    "        model.add_training_data(state, policy, value)\n",
    "\n",
    "    # 5. Training Phase\n",
    "    print(f\"Training Neural Network on {len(model.training_data)} cached examples...\")\n",
    "    model.train(batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Iteration complete in {duration:.1f}s\")\n",
    "\n",
    "print(\"\\nTraining Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7d1c0",
   "metadata": {},
   "source": [
    "### Play against the trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c869c12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248785ed",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bbe9f6e82242978815fe8da163e293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<div style=\"text-align: center; font-size: 18px; font-weight: 600; padding: 12px; b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def play_vs_human_interactive(model):\n",
    "    \"\"\"\n",
    "    Interactive widget-based game against AlphaZero with rich statistics display.\n",
    "    \"\"\"\n",
    "    game = TicTacToe()\n",
    "\n",
    "    # UI Components\n",
    "    output = widgets.Output()\n",
    "    board_buttons = [\n",
    "        [\n",
    "            widgets.Button(\n",
    "                description=\"\",\n",
    "                layout=widgets.Layout(\n",
    "                    width=\"80px\", height=\"80px\", font_size=\"32px\", font_weight=\"bold\"\n",
    "                ),\n",
    "            )\n",
    "            for _ in range(3)\n",
    "        ]\n",
    "        for _ in range(3)\n",
    "    ]\n",
    "\n",
    "    message_label = widgets.HTML(\n",
    "        value='<div style=\"text-align: center; font-size: 18px; font-weight: 600; '\n",
    "        'padding: 12px; border-radius: 6px; background: #ddf4ff; color: #0969da;\">'\n",
    "        \"Your turn! Click a cell to play as X</div>\"\n",
    "    )\n",
    "\n",
    "    new_game_button = widgets.Button(\n",
    "        description=\"New Game\",\n",
    "        button_style=\"primary\",\n",
    "        layout=widgets.Layout(width=\"150px\"),\n",
    "    )\n",
    "\n",
    "    stats_output = widgets.Output()\n",
    "\n",
    "    def get_ai_move_with_stats(game_state):\n",
    "        \"\"\"Get AI move and collect statistics\"\"\"\n",
    "        mcts = AlphaZeroMCTS(game_state, model, c_puct=1.0, num_simulations=50)\n",
    "        root = mcts.search(game_state.state())\n",
    "\n",
    "        # Collect statistics\n",
    "        stats = []\n",
    "        for action, child in sorted(root.children.items()):\n",
    "            stats.append(\n",
    "                {\n",
    "                    \"action\": action,\n",
    "                    \"visits\": child.visit_count,\n",
    "                    \"value\": child.value(),\n",
    "                    \"prior\": child.prior,\n",
    "                    \"ucb\": child.ucb_score(1.0),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Get best move\n",
    "        valid_actions, valid_probs = mcts.get_action_probabilities(\n",
    "            game_state.state(), temperature=0.0\n",
    "        )\n",
    "        best_action_idx = np.argmax(valid_probs)\n",
    "        best_action = valid_actions[best_action_idx]\n",
    "\n",
    "        return best_action, stats\n",
    "\n",
    "    def render_board():\n",
    "        \"\"\"Update button appearances\"\"\"\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                idx = i * 3 + j\n",
    "                btn = board_buttons[i][j]\n",
    "\n",
    "                if game.board[idx] == 1:\n",
    "                    btn.description = \"X\"\n",
    "                    btn.button_style = \"info\"\n",
    "                    btn.disabled = True\n",
    "                elif game.board[idx] == -1:\n",
    "                    btn.description = \"O\"\n",
    "                    btn.button_style = \"warning\"\n",
    "                    btn.disabled = True\n",
    "                else:\n",
    "                    btn.description = \"\"\n",
    "                    btn.button_style = \"\"\n",
    "                    btn.disabled = False\n",
    "\n",
    "    def set_message(msg, color=\"#0969da\"):\n",
    "        \"\"\"Update message display\"\"\"\n",
    "        bg_color = {\n",
    "            \"#0969da\": \"#ddf4ff\",\n",
    "            \"#da7a09\": \"#fff8c5\",\n",
    "            \"#2da44e\": \"#d1f4d1\",\n",
    "        }.get(color, \"#ddf4ff\")\n",
    "        message_label.value = (\n",
    "            f'<div style=\"text-align: center; font-size: 18px; font-weight: 600; '\n",
    "            f'padding: 12px; border-radius: 6px; background: {bg_color}; color: {color};\">'\n",
    "            f\"{msg}</div>\"\n",
    "        )\n",
    "\n",
    "    def show_stats(stats):\n",
    "        \"\"\"Display MCTS statistics\"\"\"\n",
    "        with stats_output:\n",
    "            clear_output(wait=True)\n",
    "            if not stats:\n",
    "                return\n",
    "\n",
    "            total_visits = sum(s[\"visits\"] for s in stats)\n",
    "            max_visits = max(s[\"visits\"] for s in stats)\n",
    "\n",
    "            html = '<div style=\"margin: 20px 0; background: #f6f8fa; border-radius: 6px; padding: 16px;\">'\n",
    "            html += '<h3 style=\"margin: 0 0 8px 0; color: #24292f;\">AlphaZero\\'s Analysis</h3>'\n",
    "            html += '<table style=\"width: 100%; border-collapse: collapse; background: white; border-radius: 6px;\">'\n",
    "            html += '<thead><tr style=\"background: #0969da; color: white;\">'\n",
    "            html += '<th style=\"padding: 10px; text-align: left;\">Position</th>'\n",
    "            html += '<th style=\"padding: 10px; text-align: left;\">Visits</th>'\n",
    "            html += '<th style=\"padding: 10px; text-align: left;\">Value (Q)</th>'\n",
    "            html += '<th style=\"padding: 10px; text-align: left;\">Prior (P)</th>'\n",
    "            html += '<th style=\"padding: 10px; text-align: left;\">UCB Score</th>'\n",
    "            html += '<th style=\"padding: 10px; text-align: left;\">Visit %</th>'\n",
    "            html += \"</tr></thead><tbody>\"\n",
    "\n",
    "            for stat in stats:\n",
    "                visit_pct = stat[\"visits\"] / total_visits * 100\n",
    "                bar_width = stat[\"visits\"] / max_visits * 100\n",
    "\n",
    "                html += '<tr style=\"border-bottom: 1px solid #d0d7de;\">'\n",
    "                html += f'<td style=\"padding: 8px 10px;\"><strong>{stat[\"action\"]}</strong></td>'\n",
    "                html += f'<td style=\"padding: 8px 10px;\">{stat[\"visits\"]}</td>'\n",
    "                html += f'<td style=\"padding: 8px 10px;\">{stat[\"value\"]:.3f}</td>'\n",
    "                html += f'<td style=\"padding: 8px 10px;\">{stat[\"prior\"]:.3f}</td>'\n",
    "                html += f'<td style=\"padding: 8px 10px;\">{stat[\"ucb\"]:.3f}</td>'\n",
    "                html += f'<td style=\"padding: 8px 10px;\">'\n",
    "                html += f'<div style=\"display: flex; align-items: center; gap: 8px;\">'\n",
    "                html += f'<div style=\"height: 20px; width: {bar_width}%; background: linear-gradient(90deg, #0969da 0%, #54aeff 100%); border-radius: 3px;\"></div>'\n",
    "                html += f\"<span>{visit_pct:.1f}%</span>\"\n",
    "                html += f\"</div></td>\"\n",
    "                html += \"</tr>\"\n",
    "\n",
    "            html += \"</tbody></table></div>\"\n",
    "            display(HTML(html))\n",
    "\n",
    "    def check_game_over():\n",
    "        \"\"\"Check if game is over and update UI\"\"\"\n",
    "        lines = [\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8],\n",
    "            [0, 3, 6],\n",
    "            [1, 4, 7],\n",
    "            [2, 5, 8],\n",
    "            [0, 4, 8],\n",
    "            [2, 4, 6],\n",
    "        ]\n",
    "\n",
    "        for line in lines:\n",
    "            if game.board[line[0]] == game.board[line[1]] == game.board[line[2]] != 0:\n",
    "                winner = (\n",
    "                    \"You win! 🎉\" if game.board[line[0]] == 1 else \"AlphaZero wins!\"\n",
    "                )\n",
    "                color = \"#2da44e\" if game.board[line[0]] == 1 else \"#da7a09\"\n",
    "                set_message(winner, color)\n",
    "                disable_all_buttons()\n",
    "                return True\n",
    "\n",
    "        if 0 not in game.board:\n",
    "            set_message(\"It's a draw!\", \"#656d76\")\n",
    "            disable_all_buttons()\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def disable_all_buttons():\n",
    "        \"\"\"Disable all board buttons\"\"\"\n",
    "        for row in board_buttons:\n",
    "            for btn in row:\n",
    "                btn.disabled = True\n",
    "\n",
    "    def on_cell_click(i, j):\n",
    "        \"\"\"Handle human move\"\"\"\n",
    "        idx = i * 3 + j\n",
    "\n",
    "        if game.board[idx] != 0 or game.current_player != 1:\n",
    "            return\n",
    "\n",
    "        # Make human move\n",
    "        game.make_move(idx)\n",
    "        render_board()\n",
    "\n",
    "        if check_game_over():\n",
    "            return\n",
    "\n",
    "        # AI's turn\n",
    "        set_message(\"AlphaZero is thinking...\", \"#da7a09\")\n",
    "        disable_all_buttons()\n",
    "\n",
    "        # Get AI move\n",
    "        action, stats = get_ai_move_with_stats(game)\n",
    "        show_stats(stats)\n",
    "\n",
    "        # Make AI move\n",
    "        game.make_move(action)\n",
    "        render_board()\n",
    "\n",
    "        if not check_game_over():\n",
    "            set_message(\"Your turn!\")\n",
    "\n",
    "    def on_new_game(_):\n",
    "        \"\"\"Reset game\"\"\"\n",
    "        nonlocal game\n",
    "        game = TicTacToe()\n",
    "        render_board()\n",
    "        set_message(\"Your turn! Click a cell to play as X\")\n",
    "        with stats_output:\n",
    "            clear_output()\n",
    "\n",
    "    # Set up button callbacks\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            # Use closure to capture i, j\n",
    "            board_buttons[i][j].on_click(lambda _, i=i, j=j: on_cell_click(i, j))\n",
    "\n",
    "    new_game_button.on_click(on_new_game)\n",
    "\n",
    "    # Layout\n",
    "    board_grid = widgets.GridBox(\n",
    "        [board_buttons[i][j] for i in range(3) for j in range(3)],\n",
    "        layout=widgets.Layout(\n",
    "            width=\"300px\",\n",
    "            grid_template_columns=\"repeat(3, 80px)\",\n",
    "            grid_gap=\"8px\",\n",
    "            margin=\"20px auto\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    controls = widgets.HBox(\n",
    "        [new_game_button], layout=widgets.Layout(justify_content=\"center\")\n",
    "    )\n",
    "\n",
    "    ui = widgets.VBox(\n",
    "        [message_label, board_grid, controls, stats_output],\n",
    "        layout=widgets.Layout(max_width=\"900px\", margin=\"0 auto\"),\n",
    "    )\n",
    "\n",
    "    render_board()\n",
    "    display(ui)\n",
    "\n",
    "\n",
    "# Play the game\n",
    "play_vs_human_interactive(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha-toe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
